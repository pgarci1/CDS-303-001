{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwzbFryS7obF"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "!pip install mlxtend\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPcE2Bho7obI",
    "outputId": "7b47580c-a125-433d-bbea-d66675d06999"
   },
   "outputs": [],
   "source": [
    "# set file location\n",
    "#if needed please choose commented format if needed\n",
    "#file_loc = Path(r'C:\\Users\\hruss\\OneDrive\\Documents\\GMU\\Repositories\\Data_files')\n",
    "file_loc = Path(r\"C:/Users/pgarc_1jof181/Desktop/titanic.csv\")\n",
    "\n",
    "#print(\"file location exists:\", file_loc.is_dir())\n",
    "print(\"file location exists:\", file_loc.is_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "qBVh3Waa7obJ",
    "outputId": "3d4cf6aa-0e6e-44ce-c68a-5e800d852857"
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "#df = pd.read_csv(\"titanic.csv\")\n",
    "df = pd.read_csv(file_loc)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neCMiswk7obJ",
    "outputId": "2f28593d-1b86-4598-af7b-5a17870b0278"
   },
   "outputs": [],
   "source": [
    "# find out number of rows and columns\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdPrp6On7obJ",
    "outputId": "51ce7f23-1d5b-4c99-eaaa-7d677483228b"
   },
   "outputs": [],
   "source": [
    "# find null values\n",
    "\n",
    "nulls = df.isnull().sum()\n",
    "print(\"These are the features with null values, and the count of null values in each.\")\n",
    "print(nulls[nulls >= 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "ZcRvuFUl7obK",
    "outputId": "348660e3-b934-45f1-cb08-bbfc08e99778"
   },
   "outputs": [],
   "source": [
    "# Impute missing 'age' values based on another ('who') column, and check\n",
    "\n",
    "category_means = df.groupby('who')['age'].transform('mean')\n",
    "df1 = df\n",
    "df1['age'].fillna(category_means, inplace=True)\n",
    "df1[df1['who'] == 'child'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "FY6sv59o7obK",
    "outputId": "a0f096bf-b522-4f76-f7ce-9da0eeaccf4e"
   },
   "outputs": [],
   "source": [
    "# try a quick association rule to see if there is some pattern to deck = NaN\n",
    "# first we create a categories dataframe\n",
    "\n",
    "df_categories = df1.drop(['pclass', 'sibsp', 'parch', 'Unnamed: 0', 'embarked', 'sex', 'age', 'fare', 'alive', 'adult_male'],axis = 1)\n",
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "70856gSF7obK",
    "outputId": "c83cfe09-be27-4cb9-e7da-312ecdc68e69"
   },
   "outputs": [],
   "source": [
    "# then we encode the category columns\n",
    "\n",
    "codes = cat_encoder.fit_transform(df_categories[['class', 'who', 'deck', 'embark_town']])\n",
    "names = cat_encoder.get_feature_names_out()\n",
    "encoded_df = pd.DataFrame(codes.todense(), columns = names)\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "LvL-TcnK7obL",
    "outputId": "cdebad71-5086-4308-cf43-0d12fb2d2788"
   },
   "outputs": [],
   "source": [
    "# then we clean things up a bit\n",
    "\n",
    "df2 = pd.merge(encoded_df, df_categories[['survived', 'alone']], left_index=True, right_index=True)\n",
    "df2['alone'].replace([0,1],[False, True], inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "_QpahHLj7obL",
    "outputId": "865d354f-62ba-4fe9-dc4f-935ad2ca6311"
   },
   "outputs": [],
   "source": [
    "# then we do some association rule mining using apriori and print the results\n",
    "\n",
    "results = apriori(df2, min_support = .2, use_colnames=True)\n",
    "results = results[results['itemsets'].apply(lambda x: len(x)) > 2]\n",
    "results = results[results['itemsets'].apply(lambda x: 'deck_nan' in x)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JKvIYLv7obM",
    "outputId": "80126960-ca81-4572-ce04-4fdf54f460d5"
   },
   "outputs": [],
   "source": [
    "# let's look at a subset of the data we suspect is most closely related to deck = NaN\n",
    "# we want to filter to: who = man, embark town = southampton, alone = true and class_third = true\n",
    "# we want the resulting table to just show the counts of each variable after filtering\n",
    "\n",
    "df2[(df2['who_man'] == True)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "8Lu7wfSe7obM",
    "outputId": "682a206d-2721-4dfd-fcbb-c2f8ae2bdc72"
   },
   "outputs": [],
   "source": [
    "# join df1 and df2 for analysis like clustering, correlation, and pca\n",
    "\n",
    "df3 = pd.concat([df1,df2], axis=0)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "BobUJemz7obN",
    "outputId": "699f9cf9-c1e8-4887-85c2-6c59951209db"
   },
   "outputs": [],
   "source": [
    "# normalize age and fare, so they don't bias our clustering and correlation\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df3['age'] = scaler.fit_transform(df3[['age']])\n",
    "df3['fare'] = scaler.fit_transform(df3[['fare']])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "VeyU2-Ec7obP",
    "outputId": "8eac37d0-564f-470a-dccd-d6046c991aa2"
   },
   "outputs": [],
   "source": [
    "# discover correlations\n",
    "\n",
    "corr_matrix = df3.corr()\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
